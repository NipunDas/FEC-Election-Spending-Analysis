# Final Project Draft
By: Nipun Das (nkdas@calpoly.edu)

### Dataset
After doing some research, I decided to pivot away from the FEC dataset that I performed EDA on last week. The dataset is fairly raw and requires some cleaning and normalization, and there are other more refined datasets that aggregate FEC data with other sources to get more useful features. Ultimately, I chose the Stanford DIME (Database on Ideology, Money in Politics, and Elections) (dataset)[https://data.stanford.edu/dime] since it contains a variety of useful features and is also up-to-date as of the 2024 election cycle, which is not the case with OpenSecrets and other election spending datasets.

### Task
By combining features about committees, candidates, and contributions, I created a contributions dataframe that tracks contributions from committees to candidates for federal-level congressional races (Senate and House of Representatives). The contributions dataframe contains contributions for one election cycle, with contribution amounts, dates, committee ID, and candidate ID, amongst other features. The goal of this project is to predict future candidate/committee donation pairs, based on prior donations. It is similar to a recommendation problem.

### Models
The models I trained were a random baseline model, heuristic model, collaborative filtering model, and random forest model. The random baseline simply randomly predicts donations, while the heuristic model works similarly to the popularity heuristics from the content recommenders in this class. For each candidate, the predicted most likely contributors are the committees that have donated the most to the political party the candidate is a member of. The 

### Evaluation
The evaluation results are shown below. As expected, the heuristic model significantly outperforms the random baseline in all metrics, with a MAP@20 of 0.0702 compared to the random baseline of 0.0019. Unfortunately, the collaborative filtering and random forest models do not perform particularly well, and are comparable to the random baseline. For the collaborative filtering model, the interaction matrix sparsity is fairly high (density = 1.79%), which could cause problems. As for the random forest model, the features used may not provide enough signal to predict donations. I believe the reason for this is that most of the provided features by default (not including the target column) are categorical, and engineering some numerical features would be beneficial for generating better regression models.

![Model Evaluation Scores](./images/model_comparison_topk20.png)

### Future Steps
The heuristic model performs well since it uses "frequent" contributors to predict who are most likely to contribute in the future, while taking political party into account. I think that the random forest model, and similar candidate/committee feature-based models like XGBoost could potentially do better given a better set of features. Taking inspiration from the heuristic model, engineering numerical features such as the amount of donations a candidate has already received or the amount of donations a committee has already provided could provide useful signal, but I didn't have time to implement these features this week since they need to be carefully engineered to avoid temporal leakage, both in the training and test datasets. As for the collaborative filtering model, I plan to epxeriment with hyperparameter tuning, such as with the number of factors, to see if I can achieve better performance with it. if so, I could ensemble it with my random forest model to improve performance, especially in the case of "cold-start" candidates/committees. Finally, I think performing clustering using latent features from the interaction matrix could provide useful insight for further understanding the dataset, and categories derived from clusters could also provide useful features.
